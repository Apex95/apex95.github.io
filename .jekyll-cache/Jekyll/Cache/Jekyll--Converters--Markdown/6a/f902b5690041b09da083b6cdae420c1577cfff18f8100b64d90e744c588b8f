I"Š<p>Today I held a short laboratory which tackled different metrics used in evaluating classifiers. One of the tasks required that, given the performances of 2 classifiers as <strong>confusion matrices</strong>, the students will calculate the <strong>accuracy</strong> of the 2 models. One model was a <strong>binary classifier</strong> and the other was a <strong>multiclass classifier</strong>.</p>

<p>Many students resorted to googling for an <strong>accuracy formula</strong> which returned the following function:</p>

<script type="math/tex; mode=display">{\color{Red}{ACC = \frac{TP + TN}{TP + TN + FP +FN}}}</script>

<p>Then, they calculated a <strong>â€˜per-classâ€™ accuracy</strong> (for class <script type="math/tex">i</script>, they had <script type="math/tex">ACC_i</script>) and <strong>macro-averaged</strong> the results like below:</p>

<script type="math/tex; mode=display">ACC = \frac{\sum_{i=1}^{i=N}{ACC_i}}{N}</script>

<p>To their surprise, the resulted accuracy for the <strong>multiclass classifier</strong> was <strong>erroneous</strong> and highly different (when compared to <code class="highlighter-rouge">accuracy_score()</code> from <strong>sklearn</strong>). However, the accuracy of the <strong>binary classifier</strong> was correct.</p>

<p>As there wasnâ€™t much time available, I told them to use the following <strong>accuracy formula</strong> and Iâ€™ll send an explaination:</p>

<script type="math/tex; mode=display">{\color{Green}{ACC = \frac{\sum_{i=1}^{i=N}{TP_i}}{\sum_{i = 1}^{i=N}{(TP_i + FP_i)}}}}</script>

<p>The purpose of this article is to serve as a list of DOâ€™s and DONTâ€™s so we can avoid such mistakes in the future.</p>

<h2 id="what-was-wrong">What was wrong?</h2>

<p>Basically, youâ€™re prone to get invalid results if you <strong>average</strong> accuracy values in an attempt to obtain the <strong>global accuracy</strong>. Butâ€¦ even if you directly calculate the <strong>global accuracy</strong> using the <span style="color:red">above formula</span>, youâ€™d get skewed values.</p>

<p>Take a look at the following classifier, described using a <strong>confusion matrix</strong>:</p>

<table class="data-table">
  <thead>
    <tr>
      <th>\</th>
      <th>Class #0</th>
      <th>Class #1</th>
      <th>Class #2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Class #0</strong></td>
      <td>0</td>
      <td>100</td>
      <td>100</td>
    </tr>
    <tr>
      <td><strong>Class #1</strong></td>
      <td>100</td>
      <td>0</td>
      <td>100</td>
    </tr>
    <tr>
      <td><strong>Class #2</strong></td>
      <td>100</td>
      <td>100</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>Youâ€™ll notice that <script type="math/tex">TP = 0</script> thus the classifier is doing a really bad job.</p>

<p>If we follow the studentsâ€™ approach and calculate the <strong>â€˜per-classâ€™ accuracy</strong> (letâ€™s say <strong>Class #0</strong>), we have:</p>

<script type="math/tex; mode=display">TP_0 = 0, TN_0 = 200, FP_0 = 200, FN_0 = 200</script>

<script type="math/tex; mode=display">\color{Red}{ACC_0 = \frac{0 + 200}{0+200+200+200} = 0.333(3)}</script>

<p>This already looks suspicious. Youâ€™ll get the same results for the other 2 classes, soâ€¦ on average, <script type="math/tex">\color{Red}{ACC = 0.333(3)}</script>.
This is definitely wrong.</p>

<p>If you directly compute <strong>global accuracy</strong> using the <span style="color:red">same formula</span> (summing all <script type="math/tex">TP's</script>, <script type="math/tex">TN's</script>, â€¦), you get the same result because of the symmetry. This happens mainly because of the <script type="math/tex">TN</script> in the numerator which grows faster than any other term. In other words, as the number of classes grows, this error grows aswell; a similar model, but with <strong>4 classess</strong>, gets a <strong>0.5</strong> accuracy.</p>

<p>Using the <span style="color:green">second formula</span>, the <strong>global accuracy</strong> becomes:</p>

<script type="math/tex; mode=display">\color{Green}{ACC = \frac{0+0+0}{(0+200) + (0+200) + (0 + 200)} = 0}</script>

<p>Which yields, indeed, a better result. Also identical to the one returned by <code class="highlighter-rouge">average_score()</code> from <strong>sklearn</strong>.</p>

<h5 id="this-is-a-favorable-example-in-which-if-you-compute-per-class-accuracies-using-the-second-formula-and-average-the-values-youll-get-the-correct-global-accuracy-this-does-not-hold-for-other-examples-so-dont-do-that">This is a favorable example, in which, if you compute <strong>â€˜per classâ€™ accuracies</strong> using the <span style="color:green">second formula</span> and average the values, youâ€™ll get the correct <strong>global accuracy</strong>. This does <strong>not hold</strong> for <strong>other examples</strong>, so donâ€™t do that.</h5>

<h2 id="conclusion">Conclusion</h2>

<p>Iâ€™d recommend avoiding:</p>
<ul>
  <li>the idea of calculating a <strong>global accuracy</strong> by averaging <strong>â€˜per-classâ€™ accuracies</strong></li>
  <li>the <span style="color:red">red formula</span>, which includes <script type="math/tex">TN</script>, since the <span style="color:green">other one</span> returns correct values for any number of classes</li>
</ul>

<p>Overall, you can compute <strong>precision</strong>, <strong>recall</strong>, <strong>F1</strong> in a â€˜per-classâ€™ manner. But Iâ€™m not so sure it also works with the <strong>accuracy</strong>.</p>

:ET