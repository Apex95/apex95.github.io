I"é&<p>This article discusses handwritten character recognition (<strong>OCR</strong>) in images using <em>sequence-to-sequence</em> (<strong>seq2seq</strong>) mapping performed by a <em>Convolutional Recurrent Neural Network</em> (<strong>CRNN</strong>) trained with <em>Connectionist Temporal Classification</em> (<strong>CTC</strong>) loss. The aforementioned approach is employed in multiple modern OCR engines for handwritten text (e.g., <a href="https://arxiv.org/pdf/1902.10525.pdf" rel="nofollow">Google‚Äôs Keyboard App</a> - convolutions are replaced with Bezier interpolations) or typed text (e.g., <a href="https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf" rel="nofollow">Tesseract 4‚Äôs CRNN Based Recognition Module</a>).</p>

<p>For the sake of simplicity, the example I‚Äôll be presenting performs only digit recognition but can be easily extended to accommodate more classes of characters.</p>

<h5 id="im-providing-a-google-colab-document-that-includes-a-working-example-of-the-concept-presented-here">I‚Äôm providing a <a href="https://colab.research.google.com/drive/1VRyObLgslpzeB33xITPdm_3E2cAxLuX3?usp=sharing" rel="nofollow">Google Colab</a> document that includes a working example of the concept presented here.</h5>

<h2 id="previous-inadequacies-and-justification">Previous Inadequacies and Justification</h2>

<blockquote>
  <p>‚ÄúWhy not simply segment characters in the image and recognize them one by one?‚Äù</p>
</blockquote>

<p>While the approach is, indeed, more straightforward and has been incorporated in older OCR engines, it has its caveats, especially when considering handwritten text. These are caused by the imperfections of the written characters which can produce segmentation issues thus attempting to recognize invalid glyphs or symbols. Consider the following images for clarification:</p>

<figure class="image">
  <img src="data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs=" data-echo="/imgs/posts/pytorch-crnn-seq2seq-digits-recognition/fragmented-characters.png" alt="A fragmented '5' is segmented as 2 different characters that are later passed to the recognition module. " />
  <figcaption><p>A fragmented ‚Äò5‚Äô is segmented as 2 different characters that are later passed to the recognition module.</p>
</figcaption>
</figure>

<figure class="image">
  <img src="data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs=" data-echo="/imgs/posts/pytorch-crnn-seq2seq-digits-recognition/merged-characters.png" alt="The first 2 digits are 'merged' together and considered a single character by both segmentation mechanism and OCR engine." />
  <figcaption><p>The first 2 digits are ‚Äòmerged‚Äô together and considered a single character by both segmentation mechanism and OCR engine.</p>
</figcaption>
</figure>

<p>Whereas the MNIST problem is considered solved thus implying that reliable classifiers can be constructed to individually recognize digits, the problem of correct segmentation still remains in realistic scenarios. Splitting or merging glyphs to form valid digits proves to be a difficult challenge and requires additional knowledge to be embedded into the segmentation module.</p>

<h2 id="seq2seq-classifications">Seq2Seq Classifications</h2>

<p>In this context, the main advantage brought by a <strong>seq2seq</strong> classifier is that it diminishes the impact of erroneous segmentations and takes advantage of the ability of a neural network to generalize. It only requires a valid segmentation of the word or text line in cause.</p>

<p>Consider the following simplistic model that has a <strong>sliding window</strong> or <strong>mask</strong> (no convolutions), of size <code class="highlighter-rouge">(1, img_height)</code>. Each set of pixels covered by the sliding window is fed into a neural network made out of neurons with <strong>memory</strong> (e.g., <strong>GRU</strong> or <strong>LSTM</strong>); the job of the neural network is to take a sequence of such stripes and output recognized digits. Take a look at the following figure:</p>

<figure class="image">
  <img src="data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs=" data-echo="/imgs/posts/pytorch-crnn-seq2seq-digits-recognition/one-digit-rnn.png" alt="The RNN learns to recognize the digit '5' only by seeing stripes of width equal to 1 of the digit in cause - think of it as time series; by combining information from previous and current inputs, the RNN can determine the correct class." />
  <figcaption><p>The RNN learns to recognize the digit ‚Äò5‚Äô only by seeing stripes of width equal to 1 of the digit in cause - think of it as time series; by combining information from previous and current inputs, the RNN can determine the correct class.</p>
</figcaption>
</figure>

<p>Multiple digits will be included in a single sequence - because we‚Äôre feeding the network an image which contains more than a digit. It is up to the neural network to determine during the training phase how many stripes to take into account when classifying a digit (i.e., how much to memorize). The image below illustrates how a RNN should ‚Äògroup‚Äô stripes together in order to recognize each digit in the sequence.</p>

<figure class="image">
  <img src="data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs=" data-echo="/imgs/posts/pytorch-crnn-seq2seq-digits-recognition/rnn-ctc-ocr.png" alt="The RNN receives sequences of 'vertical' arrays of pixels (stripes) covered by the sliding window of width equal to 1; once trained, the RNN will be able to memorize that certain sequences of arrays (here in colors) form specific digits and properly separate multiple digits (i.e., 'change the colors') even though they are merged in the given image." />
  <figcaption><p>The RNN receives sequences of ‚Äòvertical‚Äô arrays of pixels (stripes) covered by the sliding window of width equal to 1; once trained, the RNN will be able to memorize that certain sequences of arrays (here in colors) form specific digits and properly separate multiple digits (i.e., ‚Äòchange the colors‚Äô) even though they are merged in the given image.</p>
</figcaption>
</figure>

<p>Using this method, it is possible to train a neural network by simply saying that the image above contains the numbers ‚Äò<strong>55207</strong>‚Äô, without further information (e.g.: alignment, delimitations, bounding boxes etc.)</p>

<h2 id="ctc-and-duplicates-removal">CTC and Duplicates Removal</h2>

<p>CTC loss is most commonly employed to train seq2seq RNNs. It works by <strong>summing</strong> the <strong>probabilities for all possible alignments</strong>; the <strong>probability of an alignment</strong> is determined by <strong>multiplying</strong> the probabilities of having specific digits in certain slots. An alignment can be seen as a plausible sequence of recognized digits.</p>

<p>Going back to the ‚Äò<strong>55207</strong>‚Äô example, we can express the probability of the alignment \(A_55207\) as follows:</p>

\[P(A_{55207}) = P(A_1 = 5) \cdot P(A_2 = 5) \cdot P(A_3 = 2) \cdot P(A_4 = 0) \cdot P(A_5 = 7)\]

<p>To properly remove duplicates and also correctly handle numbers that contain repeating digits, the <strong>blank</strong> class is introduced, with the following rules:
1) 2 (or more) <strong>repeating digits</strong> are <strong>collapsed</strong> into a single instance of that digit unless separated by <strong>blank</strong> - this compensates for the fact that the RNN performs a classification for each stripe that represents a part of a digit (thus producing duplicates)
2) multiple <strong>consecutive blanks</strong> are <strong>collapsed</strong> into one blank - this compensates for the spacing before, after or between the digits</p>

<p>Given these aspects, there are multiple alignments that, once collapsed, lead to the correct alignment (‚Äò<strong>55207</strong>‚Äô).</p>

<p>For example:
<strong>55-55222‚Äì07</strong> once collapsed leads to ‚Äò<strong>55207</strong>‚Äô and suggests the correct sequence even though it has a different structure because of additional duplicates and blanks (marked as ‚Äò<strong>-</strong>‚Äô here). The probability of this alignment (\(A_{55-55222--07}\)) is computed as previously shown but it also includes the probabilities of the blank class:</p>

\[P(A_{55-55222--07}) = P(A_1 = 5) \cdot P(A_2 = 5) \cdot P(A_3 = -) \cdot P(A_4 = 5) \cdot P(A_5 = 5) \cdot P(A_6 = 2) \cdot P(A_7 = 2) \cdot P(A_8 = 2) \cdot P(A_9 = -) \cdot P(A_{10} = -) \cdot P(A_{11} = 0) \cdot P(A_{12} = 7)\]

<p>Finally, the CTC probability of a sequence is calculated, as previously mentioned, by summing the probabilities for all different alignments:</p>

\[P(S_{55207}) = \sum_{A \in Alignments(55207)}{A}\]

<p>When training, the neural network attempts to maximize this probability for the sequence provided as ground truth.</p>

<p>A <strong>decoding</strong> method is used to recover the text from a set of digits probabilities; a naive approach would be to pick, for <strong>each slot</strong> in the <strong>alignment</strong>, the digits with the <strong>highest probability</strong> and the collapse the result. This approach is easier to implement and might be enough for this example although <strong>beam search</strong> (i.e.: greedy approach that picks first N digits with highest probabilities, instead of only one) is employed for such tasks in larger projects.</p>

<p>I recommend reading <a href="https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c" rel="nofollow">this intuitive explanation of CTC</a> if there are still ambiguities.</p>

<h2 id="dataset-generation">Dataset Generation</h2>

<p>To avoid additional steps such as image preprocessing, segmentation and class balancing I picked a more friendly dataset - <strong>EMNIST</strong> for digits -</p>

:ET